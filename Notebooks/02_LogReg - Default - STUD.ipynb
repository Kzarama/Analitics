{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en el capítulo 4 de **Introducion to statistical learning with R**, de Gareth James, Daniea Witten, Trevor Hastie y Robert Tibshirani. Los ejemplos presentados en R en el libro fueron llevados a Python y completados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que vamos a analizar contiene los registros del histórico de las personas a las que se les ha otorgado un crédito financiero y pudieron pagarlo o no.\n",
    "La idea es poder predecir en un futuro, a partir de las variables independientes que aspirantes a un crédito tienen mas o menos riesgo de pagar.\n",
    "\n",
    "Las variables de la hoja de datos son las siguientes:\n",
    "- ID: El ID del cliente en el banco. Numérico, debe ser positivo y único\n",
    "- PudoPagar: Indica si el cliente ha podido pagar el crédito sin problemas (1) o no (0). Variable categórica binaria\n",
    "- Estudiante: Indica si el cliente es estudiante (Si) o no lo es (No). Variable categórica binaria\n",
    "- Deuda: Indica la cantidad del crédito que aún adeuda el cliente. Deben ser valores numéricos positivos o nulos\n",
    "- Ingresos: Indica el salario o demás ingresos de los que disponga. Deben ser valores numéricos positivos o nulos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendimiento y preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice un análisis exploratorio de los datos verificando la calidad de los mismos. Utilice gráficos para poder identificar posibles problemas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import KFold, cross_val_score #protocolo de evaluación\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos, que están en el mismo directorio que el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('02_creditos.csv', sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable independiente student debe convertise en variable numérica. Vamos a utilizar el método factorize, que devuelve dos objetos: un array de labels y un array con los valores únicos que se encontraron y cuyas posiciones son los nuevos valores de los factores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.student.factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo nos interesamos en el primer array, que lo vamos a utilizar para remplazar los datos del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['default2'] = data.default.factorize()[0]\n",
    "data['student2'] = data.student.factorize()[0]\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline\n",
    "ax = sns.countplot(x=\"default\", data=data)\n",
    "data.default[data.default==\"No\"].aggregate('count') / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar los valores gráficamente.\n",
    "Para que sean más lisibles y, dado que hay un gran desbalanceo entre los datos sin default y los datos con default, vamos a crear un nuevo Dataframe para poder visualizar los datos, en donde incluiremos todos los datos con default y una muestra con un porcentaje (15%) de los datos sin default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo consideramos una muestra con una parte de los clientes que no tienen default\n",
    "data_no = data[data.default2 == 0].sample(frac=0.15)\n",
    "\n",
    "# Como son pocos, tomamos todos los datos de los clientes que si tienen default\n",
    "data_yes = data[data.default2 == 1]\n",
    "data_ = data_no.append(data_yes)\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos 3 plots:\n",
    "- un scatterplot con las variables income y balance en los ejes y el color dado por la categoría del default\n",
    "- un boxplot con las distribuciones de del income para las categorías con y sin default\n",
    "- un boxplot con las distribuciones de del balance para las categorías con y sin default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ignorar los warnings que no son importantes para lo que vamos a hacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "gs = mpl.gridspec.GridSpec(1, 4)\n",
    "ax1 = plt.subplot(gs[0,:-2])\n",
    "ax2 = plt.subplot(gs[0,-2])\n",
    "ax3 = plt.subplot(gs[0,-1])\n",
    "\n",
    "# Plot de balance x income\n",
    "ax1.scatter(data_[data_.default == 'Yes'].balance, data_[data_.default == 'Yes'].income, s=40, c='orange', marker='+',\n",
    "            linewidths=1)\n",
    "ax1.scatter(data_[data_.default == 'No'].balance, data_[data_.default == 'No'].income, s=40, marker='o', linewidths='1',\n",
    "            edgecolors='lightblue', facecolors='white', alpha=.6)\n",
    "ax1.set_ylim(ymin=0)\n",
    "ax1.set_ylabel('Income')\n",
    "ax1.set_xlim(xmin=-100)\n",
    "ax1.set_xlabel('Balance')\n",
    "\n",
    "# 2 Boxplots\n",
    "c_palette = {'No':'lightblue', 'Yes':'orange'}\n",
    "sns.boxplot('default', 'balance', data=data, orient='v', ax=ax2, palette=c_palette)\n",
    "sns.boxplot('default', 'income', data=data, orient='v', ax=ax3, palette=c_palette)\n",
    "gs.tight_layout(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la variable *balance* es bastante discriminante con respecto a la variable dependiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelamiento: regresión logística vs. regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable independiente: balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar la relación estrecha entre la variable independiente *balance* con la dependiente *default* para ilustrar los problemas que tendría el utilizar la regresión linear para tareas de clasificación, al mismo tiempo que comparamos ese modelo con el de la regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero preparamos los datos en dos variables, una matriz de una sola columna para la variable predictiva y un array con los valores de la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.balance.values.reshape(-1,1) #Una columna, con las filas que se necesiten\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.default2\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el propósito de poder visualizar el resultado de los modelos de clasificación, creamos un array con todos los valores enteros entre el más pequeño y el más grande de la variable indepediente balance y predecimos el valor de la variable dependiente de estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.arange(data.balance.min(), data.balance.max()).reshape(-1,1)\n",
    "print(\"El rango de la variable balance es [{}, {}]\".format(data.balance.min(), data.balance.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo de LogReg, predecimos las probabilidades para todos los valores en el rango de la variable predictiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X,y)\n",
    "prob = clf.predict_proba(X_plot)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos el resultado de la regresión lineal en el plot izquierdo y de la regresión logística en el plot de la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Izquierda: plot de regresión lineal: se le dan los datos del eje x, del eje y, el orden polinómico\n",
    "# el nivel de confianza para un intervalo de confianza (ci), parámetros para el plot de scatter,\n",
    "# y parámetros para el plot lineal\n",
    "sns.regplot(data.balance, data.default2, order=1, ci=None,\n",
    "            scatter_kws={'color':'orange'},\n",
    "            line_kws={'color':'lightblue', 'lw':2}, ax=ax1)\n",
    "\n",
    "# Derecha: plot de regresión logística: un scatterplot con los valores del balance y del default (0/1),\n",
    "# y un plot con las probabilidades resultado de la regresión logística.\n",
    "ax2.scatter(X, y, color='orange')\n",
    "ax2.plot(X_plot, prob[:,1], color='lightblue')\n",
    "\n",
    "# Se agregan las lineas de los valores 0 y 1 y los títulos de los ejes\n",
    "for ax in fig.axes:\n",
    "    ax.hlines(1, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    ax.hlines(0, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    ax.set_ylabel('Probability of default')\n",
    "    ax.set_xlabel('Balance')\n",
    "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.])\n",
    "    ax.set_xlim(xmin=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de la regresión logística con la variable *balance* nos dan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "X = data.balance.values.reshape(-1,1)\n",
    "clf.fit(X,y)\n",
    "print(clf)\n",
    "print('clases: ',clf.classes_)\n",
    "print('coeficientes: ',clf.coef_)\n",
    "print('intercepto :', clf.intercept_)\n",
    "y_pred = clf.predict(X)\n",
    "cm= metrics.confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y, y_pred))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con la regresión lineal, scikit-learn no facilita los valores-p de la significancia de los coeficientes, por lo que utilizaremos **statsmodels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "X = sm.add_constant(data.balance)\n",
    "est = sm.Logit(y.ravel(), X).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que el coeficiente de *balance* positvo, y tiene un valor-p inferior a un nivel de significancia del 5% o del 1%, por lo que podemos decir que la relación entre balance y default es significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable independiente: student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(data.student2)\n",
    "est = sm.Logit(y.ravel(), X).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la variable *student* tiene un coeficiente positivo, lo que significa que los estudiantes son más propensos a tener default que los no estudiantes, y su valor-p es significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables independientes: balance, income y student (regresión logística múltiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(data[['balance', 'income', 'student2']])\n",
    "est = smf.Logit(y, X).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el modelo de regresión logística múltiple nos da que income no es significativa (valor-p del 71%), aunque las otras dos si.\n",
    "En este modelo múltiple, el coeficiente de *student* nos dice que los estudiantes son menos propensos al default que los no estudiantes (coeficiente negativo). \n",
    "En la regresión logística que solo consideraba *student* encontrabamos que la relación  era contraria.\n",
    "\n",
    "Esto se puede explicar por la relación entre *student* y *balance* (no incluimos *income*, al no ser significativa). \n",
    "Vamos a analizar por separado la subpoblación estudiante y la no estudiante para tratar de entender esta relación entre *student* y *default* dado la presencia de *balance*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos entre los estudiantes y los no estudiantes.\n",
    "X_stud = data[data.student == 'Yes'].balance.values.reshape(data[data.student == 'Yes'].balance.size,1) \n",
    "y_stud = data[data.student == 'Yes'].default2\n",
    "X_nostud = data[data.student == 'No'].balance.values.reshape(data[data.student == 'No'].balance.size,1) \n",
    "y_nostud = data[data.student == 'No'].default2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendemos los dos modelos de regresión para los dos datasets, solo considerando *balance* como variable independiente.\n",
    "Al igual que anteriormente, evaluamos para el rango de valores posibles de la variable *balance*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aprendizaje de los modelos\n",
    "logreg_stud   = LogisticRegression()\n",
    "logreg_nostud = LogisticRegression()\n",
    "logreg_stud.fit  (  X_stud, y_stud  )\n",
    "logreg_nostud.fit(X_nostud, y_nostud)\n",
    "\n",
    "# Evaluación de los modelos\n",
    "X_plot = np.arange(data.balance.min(), data.balance.max()).reshape(-1,1)\n",
    "prob_stud = logreg_stud.predict_proba(X_plot)\n",
    "prob_nostud = logreg_nostud.predict_proba(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stud = clf.predict(X_stud)\n",
    "cm= metrics.confusion_matrix(y_stud, y_pred_stud)\n",
    "print(cm)\n",
    "\n",
    "data.default[data.default==\"No\"].aggregate('count') / data.shape[0] * 100\n",
    "print(\"Baseline: \", (len(y_stud)-np.count_nonzero(y_stud)) / len(y_stud))\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y_stud, y_pred_stud))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_stud, y_pred_stud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nostud = clf.predict(X_nostud)\n",
    "cm= metrics.confusion_matrix(y_nostud, y_pred_nostud)\n",
    "print(cm)\n",
    "print(\"Baseline: \", (len(y_nostud)-np.count_nonzero(y_nostud)) / len(y_nostud))\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y_nostud, y_pred_nostud))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_nostud, y_pred_nostud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['student','default']).size().unstack('student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dos plots para poder entender la relación entre *student* y *balance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating plot\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Left plot\n",
    "ax1.plot(X_plot, pd.DataFrame(prob_stud)[1], color='orange', label='Estudiantes')\n",
    "ax1.plot(X_plot, pd.DataFrame(prob_nostud)[1], color='lightblue', label='No estudiantes')\n",
    "ax1.hlines(127/2817, colors='orange', label='Estudiantes, global',\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed')\n",
    "ax1.hlines(206/6850, colors='lightblue', label='No estudiantes, global',\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed')\n",
    "ax1.set_ylabel('Default')\n",
    "ax1.set_xlabel('Balance')\n",
    "ax1.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.])\n",
    "ax1.set_xlim(450,2500)\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "# Right plot\n",
    "sns.boxplot('student', 'balance', data=data, orient='v', ax=ax2,  palette=c_palette);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos a la derecha que los estudiantes tienen valores mayores de *balance* que los no estudiantes. Como las distribuciones de *balance* para estudiantes y no estudiantes son diferentes, podemos decir que hay una correlación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico de la izquierda vemos las líneas horizontales punteadas de probabilidad globales de *default* (sin considerar el balance), con la de los estudiantes por encima de la de los no estudiantes.\n",
    "Sin embargo, cuando consideramos la correlación de *student* con *balance*, encontramos que a mayores valores de balance, la probabilidad de default es mayor para los no estudiantes que para los estudiantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este caso ilustra las sutilezas asociadas a las regresiones realizadas con una sola variable, cuando otros predictores pueden ser también relevantes. También muestra los posibles efectos de las correlaciones entre predictores. Este fenómeno se llama **\"confounding\"**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
